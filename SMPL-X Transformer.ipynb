{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9408d096",
   "metadata": {},
   "source": [
    "# Imports and Configuration\n",
    "This cell imports necessary libraries including PyTorch, NumPy, and TikToken. It also sets up the configuration dictionaries for the SMPL-X input and the GPT model architecture, defines hyperparameters like batch size and learning rate, and initializes the tokenizer and computation device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a794ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import tiktoken\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cfg_smplx = {\n",
    "    \"input_dim\": 66,\n",
    "    \"padded_dim\": 72,\n",
    "    \"n_heads\": 6,\n",
    "    \"n_layers\": 10,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 100258,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 8,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 3e-4\n",
    "NUM_EPOCHS = 10\n",
    "MAX_SEQ_LEN = 300\n",
    "\n",
    "BOS_TOKEN = 100256\n",
    "EOS_TOKEN = 100257\n",
    "\n",
    "cfg = GPT_CONFIG_124M\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24648d64",
   "metadata": {},
   "source": [
    "# Robust Neural Network Modules \n",
    "Here we define helper classes and functions to improve model stability and performance. This includes RobustRMSNorm for normalization, SwiGLU for the feed-forward activation, and functions to apply Rotary Positional Embeddings (RoPE) and Stochastic Depth (DropPath)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustRMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fp32 = x.float()\n",
    "        var = x_fp32.pow(2).mean(-1, keepdim=True)\n",
    "        x_norm = x_fp32 * torch.rsqrt(var + self.eps)\n",
    "        return self.weight * x_norm.type_as(x)\n",
    "\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, drop_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w3 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.w3(F.silu(self.w1(x)) * self.w2(x)))\n",
    "\n",
    "def apply_rotary_emb(x, freqs_cis):\n",
    "    x_float = x.float()\n",
    "    x_real, x_imag = x_float.reshape(*x.shape[:-1], -1, 2).unbind(-1)\n",
    "    freqs_cos, freqs_sin = freqs_cis.unbind(-1)\n",
    "    freqs_cos = freqs_cos.unsqueeze(0).unsqueeze(2)\n",
    "    freqs_sin = freqs_sin.unsqueeze(0).unsqueeze(2)\n",
    "    x_out_real = x_real * freqs_cos - x_imag * freqs_sin\n",
    "    x_out_imag = x_real * freqs_sin + x_imag * freqs_cos\n",
    "    x_out = torch.stack([x_out_real, x_out_imag], dim=-1).flatten(3)\n",
    "    return x_out.type_as(x)\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim, end, theta=10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)\n",
    "    freqs = torch.outer(t, freqs).float()\n",
    "    return torch.stack([torch.cos(freqs), torch.sin(freqs)], dim=-1)\n",
    "\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0.0 or not self.training:\n",
    "            return x\n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "        random_tensor.floor_()\n",
    "        return x.div(keep_prob) * random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910e5aa",
   "metadata": {},
   "source": [
    "# Attention Mechanisms\n",
    "This section defines the attention layers. SafeAdvancedSelfAttention handles standard attention with support for RoPE and causal masking. SafeAdvancedCrossAttention allows the decoder to attend to the encoder's output, integrating motion information into the text generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeAdvancedSelfAttention(nn.Module):\n",
    "    def __init__(self, dim, n_heads, drop_rate=0.1, use_rope=True):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = dim // n_heads\n",
    "        self.scale = 1.0 / math.sqrt(self.head_dim)\n",
    "        \n",
    "        self.W_query = nn.Linear(dim, dim, bias=False)\n",
    "        self.W_key = nn.Linear(dim, dim, bias=False)\n",
    "        self.W_value = nn.Linear(dim, dim, bias=False)\n",
    "        self.W_out = nn.Linear(dim, dim, bias=False)\n",
    "        \n",
    "        self.q_norm = RobustRMSNorm(self.head_dim)\n",
    "        self.k_norm = RobustRMSNorm(self.head_dim)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "        self.use_rope = use_rope\n",
    "\n",
    "    def forward(self, x, freqs_cis=None, causal_mask=None, padding_mask=None):\n",
    "        b, seq, _ = x.shape\n",
    "        q = self.W_query(x).view(b, seq, self.n_heads, self.head_dim)\n",
    "        k = self.W_key(x).view(b, seq, self.n_heads, self.head_dim)\n",
    "        v = self.W_value(x).view(b, seq, self.n_heads, self.head_dim)\n",
    "        \n",
    "        q = self.q_norm(q)\n",
    "        k = self.k_norm(k)\n",
    "        \n",
    "        if self.use_rope and freqs_cis is not None:\n",
    "            freqs_cis_curr = freqs_cis[:seq]\n",
    "            q = apply_rotary_emb(q, freqs_cis_curr)\n",
    "            k = apply_rotary_emb(k, freqs_cis_curr)\n",
    "            \n",
    "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
    "        \n",
    "        attn_scores = (q.float() @ k.float().transpose(-2, -1)) * self.scale\n",
    "        \n",
    "        if causal_mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(causal_mask[:seq, :seq] == 0, float('-inf'))\n",
    "        \n",
    "        if padding_mask is not None:\n",
    "            padding_mask_expanded = padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "            attn_scores = attn_scores.masked_fill(padding_mask_expanded == 0, float('-inf'))\n",
    "        \n",
    "        attn_scores = torch.clamp(attn_scores, min=-1000, max=1000)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1).type_as(v)\n",
    "        attn_probs = self.dropout(attn_probs)\n",
    "        \n",
    "        out = (attn_probs @ v).transpose(1, 2).contiguous().view(b, seq, -1)\n",
    "        return self.W_out(out)\n",
    "\n",
    "\n",
    "class SafeAdvancedCrossAttention(nn.Module):\n",
    "    def __init__(self, dim, enc_dim, n_heads, drop_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = dim // n_heads\n",
    "        self.scale = 1.0 / math.sqrt(self.head_dim)\n",
    "        \n",
    "        self.W_q = nn.Linear(dim, dim, bias=False)\n",
    "        self.W_k = nn.Linear(enc_dim, dim, bias=False)\n",
    "        self.W_v = nn.Linear(enc_dim, dim, bias=False)\n",
    "        self.W_out = nn.Linear(dim, dim, bias=False)\n",
    "        \n",
    "        self.q_norm = RobustRMSNorm(self.head_dim)\n",
    "        self.k_norm = RobustRMSNorm(self.head_dim)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x, x_enc, enc_mask=None):\n",
    "        b, seq, _ = x.shape\n",
    "        enc_seq = x_enc.shape[1]\n",
    "        \n",
    "        q = self.W_q(x).view(b, seq, self.n_heads, self.head_dim)\n",
    "        k = self.W_k(x_enc).view(b, enc_seq, self.n_heads, self.head_dim)\n",
    "        v = self.W_v(x_enc).view(b, enc_seq, self.n_heads, self.head_dim)\n",
    "        \n",
    "        q = self.q_norm(q)\n",
    "        k = self.k_norm(k)\n",
    "        \n",
    "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
    "        \n",
    "        attn_scores = (q.float() @ k.float().transpose(-2, -1)) * self.scale\n",
    "        \n",
    "        if enc_mask is not None:\n",
    "            enc_mask_expanded = enc_mask.unsqueeze(1).unsqueeze(2)\n",
    "            attn_scores = attn_scores.masked_fill(enc_mask_expanded == 0, float('-inf'))\n",
    "        \n",
    "        attn_scores = torch.clamp(attn_scores, min=-1000, max=1000)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1).type_as(v)\n",
    "        \n",
    "        out = (self.dropout(attn_probs) @ v).transpose(1, 2).contiguous().view(b, seq, -1)\n",
    "        return self.W_out(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8b1be",
   "metadata": {},
   "source": [
    "# Transformer Blocks\n",
    "This cell defines the EncoderBlock and DecoderBlock. The encoder block consists of self-attention and a feed-forward network. The decoder block adds a cross-attention layer between the self-attention and feed-forward layers to process the encoded motion features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e6abf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b49062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dim, n_heads, drop_rate=0.1, drop_path=0.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = RobustRMSNorm(dim)\n",
    "        self.attn = SafeAdvancedSelfAttention(dim, n_heads, drop_rate, use_rope=True)\n",
    "        self.drop_path = DropPath(drop_path)\n",
    "        self.norm2 = RobustRMSNorm(dim)\n",
    "        self.ffn = SwiGLU(dim, 4*dim, drop_rate)\n",
    "\n",
    "    def forward(self, x, freqs_cis=None, padding_mask=None):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x), freqs_cis, causal_mask=None, padding_mask=padding_mask))\n",
    "        x = x + self.drop_path(self.ffn(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, dim, enc_dim, n_heads, drop_rate=0.1, drop_path=0.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = RobustRMSNorm(dim)\n",
    "        self.self_attn = SafeAdvancedSelfAttention(dim, n_heads, drop_rate, use_rope=True)\n",
    "        self.drop_path = DropPath(drop_path)\n",
    "        self.norm2 = RobustRMSNorm(dim)\n",
    "        self.cross_attn = SafeAdvancedCrossAttention(dim, enc_dim, n_heads, drop_rate)\n",
    "        self.norm3 = RobustRMSNorm(dim)\n",
    "        self.ffn = SwiGLU(dim, 4*dim, drop_rate)\n",
    "\n",
    "    def forward(self, x, x_enc, freqs_cis, causal_mask, enc_mask=None):\n",
    "        x = x + self.drop_path(self.self_attn(self.norm1(x), freqs_cis, causal_mask=causal_mask))\n",
    "        x = x + self.drop_path(self.cross_attn(self.norm2(x), x_enc, enc_mask=enc_mask))\n",
    "        x = x + self.drop_path(self.ffn(self.norm3(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d2ad8",
   "metadata": {},
   "source": [
    "# Motion Encoder \n",
    "This class projects the raw SMPL-X motion data into the model dimension and processes it through a stack of encoder blocks. It also handles the precomputation of rotary embeddings for the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedEncoder(nn.Module):\n",
    "    def __init__(self, cfg_smplx):\n",
    "        super().__init__()\n",
    "        self.input_dim = cfg_smplx['input_dim']\n",
    "        self.model_dim = cfg_smplx['padded_dim']\n",
    "        \n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.model_dim),\n",
    "            nn.LayerNorm(self.model_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(cfg_smplx['drop_rate'])\n",
    "        )\n",
    "        \n",
    "        head_dim = self.model_dim // cfg_smplx['n_heads']\n",
    "        freqs = precompute_freqs_cis(head_dim, 4096)\n",
    "        self.register_buffer('freqs_cis', freqs)\n",
    "        \n",
    "        dpr = torch.linspace(0, 0.1, cfg_smplx['n_layers']).tolist()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EncoderBlock(self.model_dim, cfg_smplx['n_heads'], cfg_smplx['drop_rate'], dpr[i])\n",
    "            for i in range(cfg_smplx['n_layers'])\n",
    "        ])\n",
    "        self.norm = RobustRMSNorm(self.model_dim)\n",
    "\n",
    "    def forward(self, x, padding_mask=None):\n",
    "        pad_amt = self.model_dim - x.shape[-1]\n",
    "        x = F.pad(x, (0, pad_amt))\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x, self.freqs_cis, padding_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b91870d",
   "metadata": {},
   "source": [
    "# GPT Model \n",
    "The main model class. It initializes the Motion Encoder and the Text Decoder. It handles the full forward pass, projecting text tokens, applying position embeddings, and running the decoder blocks which attend to the encoded motion features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.encoder = AdvancedEncoder(cfg_smplx)\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.drop = nn.Dropout(cfg['drop_rate'])\n",
    "        \n",
    "        head_dim = cfg['emb_dim'] // cfg['n_heads']\n",
    "        freqs = precompute_freqs_cis(head_dim, cfg['context_length'])\n",
    "        self.register_buffer('freqs_cis', freqs)\n",
    "        self.register_buffer('causal_mask', torch.tril(torch.ones(cfg['context_length'], cfg['context_length'])))\n",
    "        \n",
    "        dpr = torch.linspace(0, 0.1, cfg['n_layers']).tolist()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DecoderBlock(cfg['emb_dim'], cfg_smplx['padded_dim'], cfg['n_heads'], cfg['drop_rate'], dpr[i])\n",
    "            for i in range(cfg['n_layers'])\n",
    "        ])\n",
    "        \n",
    "        self.norm = RobustRMSNorm(cfg['emb_dim'])\n",
    "        self.head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.normal_(m.weight, std=0.02)\n",
    "        elif isinstance(m, nn.Embedding):\n",
    "            torch.nn.init.normal_(m.weight, std=0.02)\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate):\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters() if p.requires_grad}\n",
    "        decay = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        no_decay = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay, 'weight_decay': weight_decay},\n",
    "            {'params': no_decay, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return torch.optim.AdamW(optim_groups, lr=learning_rate)\n",
    "\n",
    "    def forward(self, tok_id, smplx_seq, enc_mask=None):\n",
    "        enc_out = self.encoder(smplx_seq, enc_mask)\n",
    "        x = self.tok_emb(tok_id)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x, enc_out, self.freqs_cis, self.causal_mask, enc_mask)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b66adae",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Helper A function to read HDF5 files containing motion sequences and text descriptions. It processes the raw text data to remove artifacts and ensures it is ready for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_data_into_memory(h5_file_path):\n",
    "    sequences = []\n",
    "    feedbacks = []\n",
    "    \n",
    "    print(f\"Loading {h5_file_path} into memory...\")\n",
    "    try:\n",
    "        with h5py.File(h5_file_path, \"r\") as h5f:\n",
    "            if \"sequences\" not in h5f or \"feedbacks\" not in h5f:\n",
    "                print(f\"Skipping {h5_file_path} (keys missing)\")\n",
    "                return [], []\n",
    "            \n",
    "            seq_ds = h5f[\"sequences\"]\n",
    "            feedback_ds = h5f[\"feedbacks\"]\n",
    "            \n",
    "            total = len(seq_ds)\n",
    "            for i in range(total):\n",
    "                seq_flat = np.array(seq_ds[i], dtype=np.float32)\n",
    "                seq = seq_flat.reshape(-1, 66)\n",
    "                sequences.append(seq)\n",
    "                \n",
    "                raw_fb = feedback_ds[i]\n",
    "                if hasattr(raw_fb, 'decode'):\n",
    "                    raw_fb = raw_fb.decode('utf-8')\n",
    "                else:\n",
    "                    raw_fb = str(raw_fb)\n",
    "                \n",
    "                raw_fb = raw_fb.replace('.,', '. ')\n",
    "                raw_fb = raw_fb.replace(\"'\", '')\n",
    "                raw_fb = raw_fb.strip()\n",
    "                \n",
    "                feedbacks.append(raw_fb)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {h5_file_path}: {e}\")\n",
    "        return [], []\n",
    "\n",
    "    return sequences, feedbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8add32ff",
   "metadata": {},
   "source": [
    "# Dataset Class\n",
    "A custom PyTorch Dataset that prepares the data for training. It handles random cropping of motion sequences and tokenizes the text, adding the required BOS and EOS tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eaf786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryMotionDataset(Dataset):\n",
    "    def __init__(self, sequences, feedbacks, tokenizer, split='train', max_len=300):\n",
    "        self.sequences = sequences\n",
    "        self.feedbacks = feedbacks\n",
    "        self.tokenizer = tokenizer\n",
    "        self.split = split\n",
    "        self.max_len = max_len\n",
    "        self.BOS = BOS_TOKEN\n",
    "        self.EOS = EOS_TOKEN\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_data = self.sequences[idx].copy()\n",
    "        \n",
    "        fb_options = self.feedbacks[idx]\n",
    "        if isinstance(fb_options, str):\n",
    "            fb_options = [fb_options]\n",
    "\n",
    "        if self.split == 'train':\n",
    "            text_str = np.random.choice(fb_options)\n",
    "        else:\n",
    "            text_str = fb_options[0]\n",
    "        text_str = str(text_str).strip()\n",
    "\n",
    "        num_frames = seq_data.shape[0]\n",
    "        if num_frames > self.max_len:\n",
    "            start_f = np.random.randint(0, num_frames - self.max_len)\n",
    "            seq_data = seq_data[start_f : start_f + self.max_len]\n",
    "        \n",
    "        smplx_tensor = torch.from_numpy(seq_data).float()\n",
    "\n",
    "        token_ids = self.tokenizer.encode(text_str)\n",
    "        token_ids = [self.BOS] + token_ids + [self.EOS]\n",
    "        text_tensor = torch.tensor(token_ids, dtype=torch.long)\n",
    "\n",
    "        return smplx_tensor, text_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b6a43c",
   "metadata": {},
   "source": [
    "# Collate Function \n",
    "This function prepares batches of data. It pads the motion sequences and text inputs to the same length within a batch and generates padding masks for the motion data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_sequence_batch(batch):\n",
    "    smplx_list = []\n",
    "    text_input_list = []\n",
    "    text_target_list = []\n",
    "    motion_lengths = []\n",
    "    \n",
    "    for smplx, text in batch:\n",
    "        smplx_list.append(smplx)\n",
    "        motion_lengths.append(len(smplx))\n",
    "        \n",
    "        text_input_list.append(text[:-1])\n",
    "        text_target_list.append(text[1:])\n",
    "\n",
    "    smplx_batch = pad_sequence(smplx_list, batch_first=True, padding_value=0.0)\n",
    "    \n",
    "    max_motion_len = smplx_batch.shape[1]\n",
    "    motion_mask = torch.zeros(len(batch), max_motion_len)\n",
    "    for i, length in enumerate(motion_lengths):\n",
    "        motion_mask[i, :length] = 1.0\n",
    "    \n",
    "    inputs_batch = pad_sequence(text_input_list, batch_first=True, padding_value=0)\n",
    "    targets_batch = pad_sequence(text_target_list, batch_first=True, padding_value=-100)\n",
    "    \n",
    "    return inputs_batch, targets_batch, smplx_batch, motion_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ea5ca0",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "The train_model function manages the training process. It loads data, splits it into train/val/test sets, runs the training epochs using mixed precision, calculates validation/test metrics, and keeps track of the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a258ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(h5_files):\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'test_loss': []\n",
    "    }\n",
    "    \n",
    "    all_seqs = []\n",
    "    all_fbs = []\n",
    "    for f in h5_files:\n",
    "        s, fb = load_hdf5_data_into_memory(f)\n",
    "        all_seqs.extend(s)\n",
    "        all_fbs.extend(fb)\n",
    "    \n",
    "    n = len(all_seqs)\n",
    "    idx1 = int(0.8 * n)\n",
    "    idx2 = int(0.9 * n)\n",
    "    \n",
    "    train_seqs, train_fbs = all_seqs[:idx1], all_fbs[:idx1]\n",
    "    val_seqs, val_fbs = all_seqs[idx1:idx2], all_fbs[idx1:idx2]\n",
    "    test_seqs, test_fbs = all_seqs[idx2:], all_fbs[idx2:]\n",
    "    \n",
    "    print(f\"Train: {len(train_seqs)}, Val: {len(val_seqs)}, Test: {len(test_seqs)}\")\n",
    "    \n",
    "    train_ds = InMemoryMotionDataset(train_seqs, train_fbs, tokenizer, 'train', MAX_SEQ_LEN)\n",
    "    val_ds = InMemoryMotionDataset(val_seqs, val_fbs, tokenizer, 'val', MAX_SEQ_LEN)\n",
    "    test_ds = InMemoryMotionDataset(test_seqs, test_fbs, tokenizer, 'test', MAX_SEQ_LEN)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                              collate_fn=collate_fn_sequence_batch, drop_last=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                            collate_fn=collate_fn_sequence_batch)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                             collate_fn=collate_fn_sequence_batch)\n",
    "    \n",
    "    model = GPTModel(cfg).to(device)\n",
    "    optimizer = model.configure_optimizers(weight_decay=0.1, learning_rate=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=LEARNING_RATE, \n",
    "        steps_per_epoch=len(train_loader), \n",
    "        epochs=NUM_EPOCHS,\n",
    "        pct_start=0.05\n",
    "    )\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    print(f\"\\nStarting Training...\")\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        batch_count = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        \n",
    "        for inputs, target, smplx, motion_mask in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            smplx = smplx.to(device)\n",
    "            motion_mask = motion_mask.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(inputs, smplx, enc_mask=motion_mask)\n",
    "                loss = F.cross_entropy(logits.flatten(0, 1), target.flatten())\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\", \"LR\": f\"{scheduler.get_last_lr()[0]:.6f}\"})\n",
    "        avg_train_loss = running_loss / batch_count\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, target, smplx, motion_mask in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                target = target.to(device)\n",
    "                smplx = smplx.to(device)\n",
    "                motion_mask = motion_mask.to(device)\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(inputs, smplx, enc_mask=motion_mask)\n",
    "                    loss = F.cross_entropy(logits.flatten(0, 1), target.flatten())\n",
    "                val_loss += loss.item()\n",
    "                val_steps += 1\n",
    "        avg_val = val_loss / val_steps if val_steps > 0 else 0\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        test_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, target, smplx, motion_mask in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                target = target.to(device)\n",
    "                smplx = smplx.to(device)\n",
    "                motion_mask = motion_mask.to(device)\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(inputs, smplx, enc_mask=motion_mask)\n",
    "                    loss = F.cross_entropy(logits.flatten(0, 1), target.flatten())\n",
    "                test_loss += loss.item()\n",
    "                test_steps += 1\n",
    "        avg_test = test_loss / test_steps if test_steps > 0 else 0\n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val)\n",
    "        history['test_loss'].append(avg_test)\n",
    "        \n",
    "        print(f\"Ep {epoch+1} | Train: {avg_train_loss:.4f} | Val: {avg_val:.4f} | Test: {avg_test:.4f}\")\n",
    "\n",
    "    torch.save({\n",
    "        'model': model.state_dict(), \n",
    "        'config': cfg,\n",
    "        'cfg_smplx': cfg_smplx,\n",
    "        'history': history\n",
    "    }, \"advanced_model_fixed.pt\")\n",
    "    print(\"Model Saved!\")\n",
    "    \n",
    "    return model, test_ds, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7119fa",
   "metadata": {},
   "source": [
    "# Overfitting Test\n",
    "This block performs a sanity check by attempting to overfit the model on a single small batch of data. If the model is implemented correctly, the loss should drop towards zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e83d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"OVERFIT TEST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model = GPTModel(cfg).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "h5_files = [r\"C:\\Users\\Zohaib\\Documents\\rehman_dataset_h5py\\motion_dataset.h5\"]\n",
    "seqs, fbs = load_hdf5_data_into_memory(h5_files[0])\n",
    "small_ds = InMemoryMotionDataset(seqs[:100], fbs[:100], tokenizer, 'train', MAX_SEQ_LEN)\n",
    "small_loader = DataLoader(small_ds, batch_size=8, shuffle=True, collate_fn=collate_fn_sequence_batch)\n",
    "\n",
    "inputs, target, smplx, motion_mask = next(iter(small_loader))\n",
    "inputs, target = inputs.to(device), target.to(device)\n",
    "smplx, motion_mask = smplx.to(device), motion_mask.to(device)\n",
    "\n",
    "print(f\"Input shape: {inputs.shape}\")\n",
    "print(f\"Target shape: {target.shape}\")\n",
    "print(f\"Motion shape: {smplx.shape}\")\n",
    "print(f\"First input tokens: {inputs[0, :5].tolist()}\")\n",
    "print()\n",
    "\n",
    "losses = []\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(inputs, smplx, enc_mask=motion_mask)\n",
    "    loss = F.cross_entropy(logits.flatten(0, 1), target.flatten())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Step {i:3d}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "print()\n",
    "if losses[-1] < 0.5:\n",
    "    print(\"✅ SUCCESS: Model can learn! Proceed with full training.\")\n",
    "else:\n",
    "    print(\"❌ FAILED: Model cannot overfit. There's a bug in the architecture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9abcc4",
   "metadata": {},
   "source": [
    "# Text Generation Function\n",
    "This function uses the trained model to generate text descriptions for new motion inputs. It implements autoregressive decoding, starting with the BOS token and stopping when the EOS token is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, smplx_input, tokenizer, max_new_tokens=50, temperature=1.0, top_k=None):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    if smplx_input.dim() == 2:\n",
    "        smplx_input = smplx_input.unsqueeze(0)\n",
    "    smplx_input = smplx_input.to(device)\n",
    "    \n",
    "    motion_mask = torch.ones(1, smplx_input.shape[1], device=device)\n",
    "\n",
    "    idx = torch.tensor([[BOS_TOKEN]], dtype=torch.long, device=device)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -1024:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond, smplx_input, enc_mask=motion_mask)\n",
    "        \n",
    "        logits = logits[:, -1, :] / temperature\n",
    "\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "            logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        if temperature > 0:\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        if idx_next.item() == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "    generated_ids = idx[0].tolist()[1:]\n",
    "    if EOS_TOKEN in generated_ids:\n",
    "        generated_ids = generated_ids[:generated_ids.index(EOS_TOKEN)]\n",
    "    \n",
    "    generated_text = tokenizer.decode(generated_ids)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af214a7",
   "metadata": {},
   "source": [
    "# Visualization Utility\n",
    "This function takes the training history dictionary and plots the training, validation, and test loss curves to visualize the model's learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231cda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_path=None):\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.plot(epochs, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "    plt.plot(epochs, history['val_loss'], 'g-s', label='Validation Loss', linewidth=2, markersize=6)\n",
    "    plt.plot(epochs, history['test_loss'], 'r-^', label='Test Loss', linewidth=2, markersize=6)\n",
    "    \n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Cross-Entropy Loss', fontsize=12)\n",
    "    plt.title('Training Progress: Motion-to-Text Model', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc='upper right', fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.xticks(epochs)\n",
    "    \n",
    "    min_val_epoch = history['val_loss'].index(min(history['val_loss'])) + 1\n",
    "    min_val_loss = min(history['val_loss'])\n",
    "    plt.annotate(f'Best Val: {min_val_loss:.4f}', \n",
    "                 xy=(min_val_epoch, min_val_loss),\n",
    "                 xytext=(min_val_epoch + 0.5, min_val_loss + 0.05),\n",
    "                 fontsize=10, color='green',\n",
    "                 arrowprops=dict(arrowstyle='->', color='green', lw=1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5df585",
   "metadata": {},
   "source": [
    "# Main Execution\n",
    "Training This is the main entry point for the script. It defines the dataset paths, initiates the training process, and then plots the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_files = [\n",
    "        r\"C:\\Users\\Zohaib\\Documents\\rehman_dataset_h5py\\motion_dataset.h5\",\n",
    "        r\"C:\\Users\\Zohaib\\Documents\\rehman_dataset_h5py\\motion_dataset_02.h5\",\n",
    "        r\"C:\\Users\\Zohaib\\Documents\\rehman_dataset_h5py\\motion_dataset_03.h5\"\n",
    "    ]\n",
    "    \n",
    "model, test_ds, history = train_model(h5_files)\n",
    "plot_training_history(history, save_path=\"training_loss_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b016101",
   "metadata": {},
   "source": [
    "# Loading a Saved Model\n",
    "This cell provides code to reload the model architecture and state dictionary from a saved checkpoint file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(cfg).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('advanced_model_fixed.pt', weights_only=True))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f649ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
